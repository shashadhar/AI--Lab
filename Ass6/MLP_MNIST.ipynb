{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecdd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "#from mnist import MNIST\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as matplot\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "matplot.rcdefaults()\n",
    "from time import time\n",
    "from IPython.display import display, HTML\n",
    "from itertools import chain\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c4ead76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "(trainX, trainy), (X_test, Y_test) = mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "724da8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "Iteration 1, loss = 24643.68645170\n",
      "Iteration 2, loss = 26149.49418070\n",
      "Iteration 3, loss = 26141.66292027\n",
      "Iteration 4, loss = 26133.82218352\n",
      "Iteration 5, loss = 26125.98384606\n",
      "Iteration 6, loss = 26118.14789477\n",
      "Iteration 7, loss = 26110.31425173\n",
      "Iteration 8, loss = 26102.48314216\n",
      "Iteration 9, loss = 26094.65405128\n",
      "Iteration 10, loss = 26086.82758765\n",
      "Iteration 11, loss = 26079.00336595\n",
      "Iteration 12, loss = 26071.18158552\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training set score: 0.112383\n",
      "Test set score: 0.113400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "                    max_iter=480, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, \n",
    "                    tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "print(trainX.shape, trainy.shape)\n",
    "\n",
    "nsamples, nx, ny = trainX.shape\n",
    "d2_train_dataset = trainX.reshape((nsamples,nx*ny))\n",
    "\n",
    "mlp.fit(d2_train_dataset, trainy)\n",
    "print(\"Training set score: %f\" % mlp.score(d2_train_dataset, trainy))\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "d2_test_dataset = X_test.reshape((nsamples,nx*ny))\n",
    "\n",
    "print(\"Test set score: %f\" % mlp.score(d2_test_dataset, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e49b1c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.11      0.20      9999\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11     10000\n",
      "   macro avg       0.10      0.01      0.02     10000\n",
      "weighted avg       1.00      0.11      0.20     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, mlp.predict(d2_test_dataset)))\n",
    "confusion_matrix(mlp.predict(d2_test_dataset), Y_test)\n",
    "print(classification_report(mlp.predict(d2_test_dataset), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfa162",
   "metadata": {},
   "source": [
    "(a) Find a good combination of parameter values for the MLPClassifier that provides the best accuracy on the 10,000 test images. Describe your parameter choices and why you believe these values are good choices.\n",
    "\n",
    "We choose Alpha and Max_iter as the parameter to run the model on and select the best from those.\n",
    "\n",
    "According to Scikit Learn- MLP classfier documentation,\n",
    "Alpha is L2 or ridge penalty (regularization term) parameter.\n",
    "Max_iter is Maximum number of iterations, the solver iterates until convergence.\n",
    "So, these ones makes sense as we could see some changing values of accuracy while tuning them,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d65d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "df = pd.DataFrame(columns = ['alpha','max_iter','train_acc','test_acc','train_time'])\n",
    "for a in [0.00001,0.0001,0.001,0.01, 0.1, 1, 10]:\n",
    "    for mi in [10,100,200,500,1000,2000]:\n",
    "        st = time()\n",
    "        mlp = MLPClassifier(alpha=a, max_iter=mi)\n",
    "        mlp.fit(d2_train_dataset, trainy)\n",
    "        end = time() - st\n",
    "        \n",
    "        acc_tr = accuracy_score(trainy, mlp.predict(d2_train_dataset)) # Train Accuracy\n",
    "        acc = accuracy_score(Y_test, mlp.predict(d2_test_dataset)) # Test Accuracy\n",
    "        df.loc[i] = [a,mi,acc_tr,acc,end]\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4829af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc_tr = []\n",
    "timelog = []\n",
    "for l in [10,20,50,100,200,500,1000]:\n",
    "    t = time()\n",
    "    mlp = MLPClassifier(alpha=0.1, max_iter=200, hidden_layer_sizes=(l,))\n",
    "    mlp.fit(d2_train_dataset, trainy)\n",
    "    endt = time() - t\n",
    "        \n",
    "    a_tr = accuracy_score(trainy, mlp.predict(d2_train_dataset)) # Train Accuracy\n",
    "    a = accuracy_score(Y_test, mlp.predict(d2_test_dataset)) # Test Accuracy\n",
    "\n",
    "    acc_tr.append(a_tr)\n",
    "    acc.append(a)\n",
    "    timelog.append(endt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d90795",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [10,20,50,100,200,500,1000]\n",
    "N = len(l)\n",
    "l2 = np.arange(N)\n",
    "matplot.subplots(figsize=(10, 5))\n",
    "matplot.plot(l2, acc, label=\"Testing Accuracy\")\n",
    "matplot.plot(l2, acc_tr, label=\"Training Accuracy\")\n",
    "matplot.xticks(l2,l)\n",
    "matplot.grid(True)\n",
    "matplot.xlabel(\"Hidden Layer Nodes\")\n",
    "matplot.ylabel(\"Accuracy\")\n",
    "matplot.legend()\n",
    "matplot.title('Accuracy versus Nodes in the Hidden Layer for MLPClassifier', fontsize=12)\n",
    "matplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1330bb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
